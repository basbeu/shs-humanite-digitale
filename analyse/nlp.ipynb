{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python library imports\n",
    "# From ADA tutorial on NLP\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import os, codecs, string, random\n",
    "import numpy as np\n",
    "from numpy.random import seed as random_seed\n",
    "from numpy.random import shuffle as random_shuffle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#NLP libraries\n",
    "import spacy, nltk, gensim, sklearn\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "#Vader\n",
    "import vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#Scikit imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# print redirect\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "df = df[df.journal != 'NZZ']\n",
    "\n",
    "start_date = '1914-08-00'\n",
    "end_date = '1914-10-00'\n",
    "keywords = [\n",
    "        'Belgique'\n",
    "]\n",
    "filters =  pd.Series([True for i in range(0, len(df))])\n",
    "for keyword in keywords:\n",
    "    filters &= df.fulltext.str.contains(keyword)\n",
    "df_filtered = df[filters\n",
    "        & (df.date >= start_date)\n",
    "        & (df.date <= end_date)]\n",
    "\n",
    "print(len(df_filtered), len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FranÃ§ais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')\n",
    "df = df[df.journal != 'NZZ']\n",
    "\n",
    "start_date = '1914-08-00'\n",
    "end_date = '1914-10-00'\n",
    "keywords = [\n",
    "        'Belgique'\n",
    "]\n",
    "filters =  pd.Series([True for i in range(0, len(df))])\n",
    "for keyword in keywords:\n",
    "    filters &= df.fulltext.str.contains(keyword)\n",
    "df_filtered = df[filters\n",
    "        & (df.date >= start_date)\n",
    "        & (df.date <= end_date)]\n",
    "\n",
    "print(len(df_filtered), len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\".join(df_filtered[['title', 'fulltext']].apply(lambda x :' '.join(x.astype(str)),1).to_numpy())\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 3000000\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [(token.lemma_, token.pos_) for token in doc if not token.is_stop]\n",
    "pipeline = [n for n, type in pipeline if type not in ['PUNCT', 'DET', 'ADP', 'PRON', 'SCONJ']]\n",
    "pipeline = list([(t, pipeline.count(t)) for t in set(pipeline)])\n",
    "pipeline.sort(key=(lambda el: el[1]), reverse=True)\n",
    "with open('results.txt', 'w+') as f:\n",
    "    with redirect_stdout(f):\n",
    "        for n, c in pipeline:\n",
    "            print(f\"{c:4d}\\t\\t{n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deutsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfde = pd.read_csv('../data/data.csv')\n",
    "dfde = dfde[dfde.journal == 'NZZ']\n",
    "\n",
    "start_date = '1914-08-00'\n",
    "end_date = '1914-10-00'\n",
    "\n",
    "keywords = [\n",
    "        'Belgien'\n",
    "]\n",
    "filters =  pd.Series([True for i in range(0, len(df))])\n",
    "for keyword in keywords:\n",
    "    filters &= dfde.fulltext.str.contains(keyword)\n",
    "filters\n",
    "\n",
    "dfde_filtered = dfde[filters\n",
    "        & (dfde.date >= start_date)\n",
    "        & (dfde.date <= end_date)]\n",
    "print(len(dfde_filtered), len(dfde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textde = \"\".join(dfde_filtered[['title', 'fulltext']].apply(lambda x :' '.join(x.astype(str)),1).to_numpy())\n",
    "len(textde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpde = spacy.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpde.max_length = 8000000\n",
    "docde = nlpde(textde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [(token.lemma_, token.pos_) for token in docde if not token.is_stop]\n",
    "pipeline = [n for n, type in pos_tagged if type not in ['PUNCT', 'DET', 'ADP', 'PRON', 'SCONJ']]\n",
    "pipeline = list([(t, pipeline.count(t)) for t in set(pipeline)])\n",
    "pipeline.sort(key=(lambda el: el[1]), reverse=True)\n",
    "with open('results.txt', 'w+') as f:\n",
    "    with redirect_stdout(f):\n",
    "        for n, c in pipeline:\n",
    "            print(f\"{c}\\t\\t{n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
