{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python library imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import os, codecs, string, random\n",
    "import numpy as np\n",
    "from numpy.random import seed as random_seed\n",
    "from numpy.random import shuffle as random_shuffle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "#seed = 42\n",
    "#random.seed(seed)\n",
    "#np.random.seed(seed)\n",
    "\n",
    "#NLP libraries\n",
    "#import spacy, nltk, gensim, sklearn\n",
    "#import pyLDAvis.gensim\n",
    "\n",
    "#Vader\n",
    "#import vaderSentiment\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#Scikit imports\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn import preprocessing\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "# print redirect\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select French journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.journal != 'NZZ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 186498\n"
     ]
    }
   ],
   "source": [
    "#start_date = '1914-01-01'\n",
    "#end_date = '1918-12-31'\n",
    "\n",
    "#start_date = '1914-07-28'\n",
    "#end_date = '1918-11-11'\n",
    "\n",
    "start_date = '1914-08-00'\n",
    "end_date = '1914-10-00'\n",
    "\n",
    "\n",
    "keywords = [\n",
    "        'Belgique'\n",
    "]\n",
    "filters =  pd.Series([True for i in range(0, len(df))])\n",
    "for keyword in keywords:\n",
    "    filters &= df.fulltext.str.contains(keyword)\n",
    "filters\n",
    "\n",
    "#'|'.join(keywords)\n",
    "\n",
    "df_filtered = df[filters\n",
    "        & (df.date >= start_date)\n",
    "        & (df.date <= end_date)]\n",
    "print(len(df_filtered), len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IramuteQ output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./iramuteq/test'+'_'.join(keywords)+start_date+'_'+end_date+'.txt', 'w+', encoding='utf-8') as f:\n",
    "    with redirect_stdout(f):\n",
    "        for index, row in df_filtered.iterrows():\n",
    "            date = datetime.datetime.strptime(row.date, '%Y-%m-%d').strftime(\"%d%m%Y\")\n",
    "            #print(f\"**** *{row.title} *{row.journal} *{row.date}\")\n",
    "            print(f\"**** *page_1 *publi_{row.journal} *date_{date}\")\n",
    "            print(row.fulltext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\".join(df[['title', 'fulltext']].apply(lambda x :' '.join(x.astype(str)),1).to_numpy())\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = len(text)*2\n",
    "doc = nlp(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
